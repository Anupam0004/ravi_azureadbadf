# Databricks notebook source
# MAGIC %md
# MAGIC # Notebook magic commands

# COMMAND ----------

# MAGIC %md
# MAGIC A notebook contains multiple cells. Each cell has a specific type. 
# MAGIC 
# MAGIC A default programming language is configured when creating the notebook and it will be implicitly used for new cells.
# MAGIC 
# MAGIC #### Magic commands
# MAGIC 
# MAGIC We can override the cell's default programming language by using one of the following *magic commands* at the start of the cell:
# MAGIC 
# MAGIC * `%python` for cells running python code
# MAGIC * `%scala` for cells running scala code
# MAGIC * `%r` for cells running R code
# MAGIC * `%sql` for cells running sql code
# MAGIC   
# MAGIC Additional magic commands are available:
# MAGIC 
# MAGIC * `%md` for descriptive cells using markdown
# MAGIC * `%sh` for cells running shell commands
# MAGIC * `%run` for cells running code defined in a separate notebook
# MAGIC * `%fs` for cells running code that uses `dbutils` commands

# COMMAND ----------

# MAGIC %md
# MAGIC To run a cell use one of the following options:
# MAGIC   * **CTRL+ENTER** or **CMD+RETURN**
# MAGIC   * **SHIFT+ENTER** or **SHIFT+RETURN** to run the cell and move to the next one
# MAGIC   * Using **Run Cell**, **Run All Above** or **Run All Below** as seen here<br/><img style="box-shadow: 5px 5px 5px 0px rgba(0,0,0,0.25); border: 1px solid rgba(0,0,0,0.25);" src="https://files.training.databricks.com/images/notebook-cell-run-cmd.png"/>

# COMMAND ----------

# MAGIC %md
# MAGIC # File System Operations

# COMMAND ----------

# MAGIC %md
# MAGIC ## Interacting with File Systems
# MAGIC Let us understand how to interact with file system using `%fs` command from Databricks Notebook.
# MAGIC 
# MAGIC * We can access datasets using `%fs` magic command in Databricks notebook
# MAGIC * By default, we will see files under `dbfs:/` 
# MAGIC * We can list the files using ls command - e. g.: ` (%fs ls)`
# MAGIC * Databricks provides lot of datasets for free under databricks-datasets
# MAGIC * by default it will look the files under dbfs root location. `dbfs:/`
# MAGIC * if you are looking for outside dbfs location and core file system like linux then use `file:/`
# MAGIC * List of commands available under `%fs`
# MAGIC * Copying files or directories `-cp`
# MAGIC * Moving files or directories `- mv `
# MAGIC * Creating directories ` - mkdirs ` 
# MAGIC * Deleting files and directories ` - rm `
# MAGIC * reading a file `head`
# MAGIC * We can copy or delete directories recursively using ` -r` or `--recursive`

# COMMAND ----------

# MAGIC %md ##### DBFS root
# MAGIC * The default storage location in DBFS is known as the DBFS root. Several types of data are stored in the following DBFS root locations:
# MAGIC 
# MAGIC * `/FileStore`: Imported data files, generated plots, and uploaded libraries. See FileStore.
# MAGIC * `/databricks-datasets`: Sample public datasets.
# MAGIC * `/databricks-results`: Files generated by downloading the full results of a query.
# MAGIC * `/databricks/init`: Global and cluster-named (deprecated) init scripts.
# MAGIC * `/user/hive/warehouse`: Data and metadata for non-external Hive tables.

# COMMAND ----------

dbutils.fs.help()

# COMMAND ----------

# MAGIC %md
# MAGIC # DBFS operations
# MAGIC 
# MAGIC 1.  listing files and folders  using `ls`
# MAGIC 2.  Create a directory using `mkdirs`
# MAGIC 3.  creating a file using `put`
# MAGIC 4.  reading a file  using `head`
# MAGIC 5.  Copy a file  using `cp`
# MAGIC 6.  move a file using `mv`
# MAGIC 7.  Delete a file using `rm`
# MAGIC 8.  Delete a directory `rm -r`  for non empty directory with `recursively`
# MAGIC 9.  list mount paths using `mounts`

# COMMAND ----------

# MAGIC %md
# MAGIC ### 1. List contents of the scratch directory

# COMMAND ----------

# MAGIC %md
# MAGIC We got this errror because the directory already exists

# COMMAND ----------

# MAGIC %fs ls /databricks-datasets

# COMMAND ----------

display(dbutils.fs.ls("/databricks-datasets"))

# COMMAND ----------

# MAGIC %md
# MAGIC ### 2 creating directory

# COMMAND ----------

# MAGIC %fs mkdirs /batch28

# COMMAND ----------

dbutils.fs.mkdirs("/batch28")

# COMMAND ----------

# MAGIC %md
# MAGIC ### 3. creating a file
# MAGIC * `-f ` option for forcefully or overwrite while using `%fs`
# MAGIC * `dbutils.fs.put(filename,data,True)`

# COMMAND ----------

# MAGIC %fs put -f "/batch28/dept.csv" """DEPTNO,DNAME,LOC
# MAGIC 10,ACCOUNTING,NEW YORK
# MAGIC 20,RESEARCH,DALLAS
# MAGIC 30,SALES,CHICAGO
# MAGIC 40,OPERATIONS,BOSTON
# MAGIC """

# COMMAND ----------

dbutils.fs.put("/batch28/dept.csv","""DEPTNO,DNAME,LOC
10,ACCOUNTING,NEW YORK
20,RESEARCH,DALLAS
30,SALES,CHICAGO
40,OPERATIONS,BOSTON
""",True)

# COMMAND ----------

# MAGIC %md
# MAGIC ### 4 reading a file

# COMMAND ----------

# MAGIC %fs head /batch28/dept.csv

# COMMAND ----------

dbutils.fs.head("/batch28/dept.csv")

# COMMAND ----------

# MAGIC %md
# MAGIC ### 5 copying a file

# COMMAND ----------

# MAGIC %fs cp "/batch28/dept.csv" "/batch28/deptcopy.csv"

# COMMAND ----------

dbutils.fs.cp("/batch28/dept.csv","/batch28/deptcopy.csv")

# COMMAND ----------

# MAGIC %fs
# MAGIC ls /batch28/

# COMMAND ----------

# MAGIC %md
# MAGIC ### 6 moving a file

# COMMAND ----------

# MAGIC %fs mv "/batch28/dept.csv" "/batch28/dept_mv.csv"

# COMMAND ----------

#dbutils.fs.mv("/batch28/dept.csv","/batch28/dept_mv.csv")

# COMMAND ----------

display(dbutils.fs.ls("/batch28/"))

# COMMAND ----------

# MAGIC %md
# MAGIC ### 7 delete a file

# COMMAND ----------

# MAGIC %fs rm "/batch28/dept_mv.csv"

# COMMAND ----------

#dbutils.fs.rm("/batch28/dept_mv.csv")

# COMMAND ----------

# MAGIC %md
# MAGIC ### 8 Delete folders and files recursively 

# COMMAND ----------

# MAGIC %fs rm -r  "/batch28/" 

# COMMAND ----------

# %fs rm -r /batch28 for removing recursively in %fs magic command
dbutils.fs.rm("/batch28/",recurse=True)

# COMMAND ----------

# MAGIC %md
# MAGIC ### 9 list mounted paths using `mounts`

# COMMAND ----------

# MAGIC %fs mounts

# COMMAND ----------

display(dbutils.fs.mounts())

# COMMAND ----------

# MAGIC %md
# MAGIC # bash commands in databricks

# COMMAND ----------

# MAGIC %%bash
# MAGIC find /databricks -name "*.csv" | grep "fa"

# COMMAND ----------

# MAGIC %md
# MAGIC # Shell commands or scripts

# COMMAND ----------

# MAGIC %sh ls

# COMMAND ----------

# MAGIC %md
# MAGIC The `mount` command allows to use remote storage as if it were a local folder available in the Databricks workspace
# MAGIC 
# MAGIC ```
# MAGIC dbutils.fs.mount(
# MAGIC   source = f"wasbs://dev@{data_storage_account_name}.blob.core.windows.net",
# MAGIC   mount_point = data_mount_point,
# MAGIC   extra_configs = {f"fs.azure.account.key.{data_storage_account_name}.blob.core.windows.net": data_storage_account_key})
# MAGIC ```

# COMMAND ----------

# default data bases and tables location
spark.conf.get("spark.sql.warehouse.dir")
